# Sistemas distribuidos y paralelos - Trabajo sobre memoria compartida

Dicho proyecto es un Trabajo Integrador realizado para la materia Sistemas distribuidos y paralelos correspondiente al plan de estudio de la carrera Ingeniería en
computación de la Universdad Nacional de la Plata.

## Objetivo

El trabajo consiste en la resolución de dos algoritmos diferentes realizando su implementación
secuencial y a su vez su paralelización. En ambos ejercicios el algoritmo secuencial debe ser lo más
óptimo posible. Por otra parte también se deben realizar cálculos de tiempos de ejecución, junto con su Speedup y
Eficiencia.

#A-1 Optimización de algoritmos secuenciales y modelo de memoria compartida
En la primera parte del trabajo integrador se nos pide trabajar con el uso de memoria compartida
mediante las librerías de Pthread y OpenMP, para la resolución de la siguiente expresión:
● A es una matriz de N x N.
● L y U son matrices de NxN triangulares inferior y superior, respectivamente.
● Los escalares minA y maxA son el mínimo y el máximo valor de los elementos de la matriz
A, respectivamente.
● El escalar promA es el valor promedio de los elementos de la matriz A.

Para la ejecución del código paralelo se nos pide realizarlo con matrices de tamaño igual a 512, 1024,
2048 y mediante el uso de 2 y 4 hilos.

### Informe del Proyecto

Para mas información acerca de este Proyecto puede acceder al Informe donde se detalla el mismo: [Informe Final.](https://github.com/Abbo17/Demodulaci-n-de-se-ales-con-Dongle-SDR1/blob/master/Informe%20Final.pdf) 

